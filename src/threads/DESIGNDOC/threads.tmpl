			+--------------------+
			|       CS 124       |
			| PROJECT 3: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Vaibhav Anand <vanand@caltech.edu>
Nikhil  Gupta <nkgupta@caltech.edu>
Michael Hashe <mhashe@caltech.edu>


>> Specify how many late tokens you are using on this assignment:

2 late tokens.  


>> What is the Git repository and commit hash for your submission?
   (You only need to include the commit-hash in the file you submit
   on Moodle.)

Repository URL:  https://github.com/MichaelHashe/CS124-OS
commit        :                                                                 TODO

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.
                                                                                TODO
>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course instructors.


			      THREADS
			      =======

---- LOGISTICS ----

These questions will help us to keep track of the difficulty level of
assignments, as well as keeping track of which team members worked on
which parts.


>> L1: How many hours did each team member spend on this assignment?
   Make sure that each member's total time is listed.

Vaibhav: ~6+5+10+4+4+SUN                                                        TODO
Nikhil : 20 hours
Michael: 20 hours


>> L2: What did each team member focus on for this assignment?  Keep
   descriptions to 25-30 words or less.

Vaibhav: alarm clock, priority set, and advanced scheduler.
Nikhil:  priority donation, locks/synchronization, condvar.
Michael: priority preemption, fixedp struct implementaiton.


			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

No data structures were altered in this portion of the project.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

The function first checks that interrupts are enabled, at which point it 
disables interrupts and stores its argument ("ticks") in the corresponding
thread structure ("ticks_until_wake"). It then blocks.

When the thread is unblocked, it re-enables interrupts and returns.


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

The majority of time is spent in the subroutine "thread_ticks", which 
updates certain statistics and decrements "ticks_until_wakes" counters. This
is a farily light-weight series of operations.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

Race conditions are avoided in timer_sleep() by disabling interrupts while      TODO
changing the thread struct and blocking. Whichever call to timer_sleep() is 
able to disable interrupts first will be able to block and sleep first.


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

It disables interrupts when it schedules itself to awaken later and blocks, 
so it cannot be interrupted by another timer interrupts during that time.


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We could have created a queue of sleeping threads instead, but this is 
an unnecessary complication (although it might scale better for many threads).

We could also have reduced timer overhead by registering the interrupt at a 
lower frequency, or potentially by having multiple timer interrupts. However,
this might lead to difficulties with race conditions.


			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

A default value for "ticks_until_wake" when a thread is not asleep.

#define THREAD_AWAKE -1  


Several attributes were added to the thread struct. A "ticks_until_wake" 
attribute was added to assist in timed sleep. "Nice" and "recent_cpu" values
were for use in MLFQS priority computations. Since "priority" can be changed
through priority donations, threads keep track of their original 'base' 
priority in the attibute "priority_org". To allow threads to compute their
priority (= max(priority_org, donated priorities)), a list "locks" was added.
Since locks keep track of their holders, this allows for priority to be
calculated whenever needed. To allow a thread to donate its priority, a
"blocked_lock" attribute was added; whenever a thread is blocked on a lock, it 
uses this attribute to signal the holder of said lock to recompute its 
priority.

struct thread {
    /*! Owned by thread.c. */
    /**@{*/
    tid_t tid;                          /*!< Thread identifier. */
    enum thread_status status;          /*!< Thread state. */
    char name[16];                      /*!< Name (for debugging purposes). */
    uint8_t *stack;                     /*!< Saved stack pointer. */
    int priority;                       /*!< Priority. */
    struct list_elem allelem;           /*!< List element for allthreads list.*/
    /**@}*/

    /* User-added stuff. */
    int64_t ticks_until_wake;           /*!< Ticks until done sleeping. */
    int nice;                           /*!< Nice value. */
    fixedp recent_cpu;                  /*!< Recent cpu time. */

    int priority_org;                   /*!< Stores original priority when
                                             when elevated. */
    struct list locks;                  /*!< Locks which thread owns. */
    struct lock *blocked_lock;           /*!< Lock which thread wants. */

    /*! Shared between thread.c and synch.c. */
    /**@{*/
    struct list_elem elem;              /*!< List element. */
    /**@}*/

#ifdef USERPROG
    /*! Owned by userprog/process.c. */
    /**@{*/
    uint32_t *pagedir;                  /*!< Page directory. */
    /**@{*/
#endif

    /*! Owned by thread.c. */
    /**@{*/
    unsigned magic;                     /* Detects stack overflow. */
    /**@}*/
};


The lock struct was changed to add an elem variable, which allows them to be 
stored in lists by their (thread) owner.

struct lock {
    struct thread *holder;      /*!< Thread holding lock (for debugging). */
    struct semaphore semaphore; /*!< Binary semaphore controlling access. */

    struct list_elem elem;      /*!< So threads know which locks they have. */
};


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Each thread maintains a list of the locks that it owns. Since a thread now has
access to the list of locks, it has access to all the threads that are waiting
on those locks, from which it can easily calculate its running priority by
taking the max of all the threads that are waiting on it and itself. This
recalculate_priority function is called whenever a thread might change priority,
like in set_priority and acquire_lock (when it might have a higher priority
donated to it). It is also implicitly called in release_lock because priority
might be taken away from it.


TIME 1:  T1 (Low)  -----> [Lock A]      (T1 has lock A)
                              |
                              |         (T2 wants lock A)
                              |
TIME 2:                      T2 (Med) ---> [Lock B]         (T3 has lock B)
Time 3:     (Med)  T2 donates to T1           |             
                                              |             (T3 wants lock B)
                                              |
TIME 4:                                      T3 (High)
TIME 5:                         (High)  T3 donates to T2 in lock_acquire via 
                                        recalculate_priority on T2

TIME 6:     (High)          recalculate_priority sees that T2 is blocked so it
                            recursively recalculates the priority for the owner
                            of the lock T2 is blocked on

TIME 7:     (Low)           T1 releases lock A and loses all priority donation
TIME 8:                     T2 (High) ---> [Lock A, Lock B]
                                                      |  
                                                      |  
                                                      |  
                                                     T3 (High)
TIME 9:                   (Med)    T2 releases locks A and B and loses donation
TIME 10:                                             T3 (High) ---> [Lock B]


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Anytime a thread needs to removed from the list of waiters (waiting threads),
the highest priority thread is unblocked. For semaphores (and therefore locks),
this is done by finding the max priority of the waiters. For condvars, this is
done by iterating over all the semaphores, and finding the priority associated
with the waiter on each of those semaphores and taking the max one.


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

An example of a race condition would be if a timer interrupt occurred during a
call to thread_set_priority(), which was changing a thread to a lower priority
but it never yielded when it was supposed to due to the interrupt. When the
interrupt returns, it may no longer valid that it doesn't have the highest
priority (and it should yield), but it will yield incorrectly anyways.

Also, since comparisons are made on the state of the ready queue, it makes 
sense to disable interrupts, so that this object is not modified simultaneously 
by another thread.

These condition are avoided in thread_set_priority by disabling interrupts 
during its execution.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We went through multiple iterations for the design of the priority donation
system. At first, we tried maintaining explicit priority donations for each
thread but that did not scale well. As such, we decided on the design where
whenever a thread might change priority, to recalculate the priority it is going
to run under.


			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* Thread niceness values. */
#define NICE_MIN -20                    /*!< Lowest niceness. */
#define NICE_INIT 0                     /*!< Niceness of init thread. */
#define NICE_MAX 20                     /*!< Highest niceness. */

/* Multi-level feedback queue scheduling. */
/* Number of ticks between recalculations of priority. */
#define PRI_RECALC_PERIOD 4
/* Initial values of load_avg and recent_cpu in initial thread. */
#define LOAD_AVG_INIT 0
#define RECENT_CPU_INIT 0
/* Number of ticks in interval used for averaging load into load_avg. */
#define LOAD_AVG_PERIOD 6000
/* Coefficient of momentum in calculating load_avg. */
#define LOAD_AVG_MOMENTUM fixedp_divide(fixedp_from_int(LOAD_AVG_PERIOD - TIMER_FREQ), fixedp_from_int(LOAD_AVG_PERIOD))
/* Coefficient of decay in calculating load_avg. */
#define LOAD_AVG_DECAY    fixedp_divide(fixedp_from_int(TIMER_FREQ), fixedp_from_int(LOAD_AVG_PERIOD))

typedef int fixedp;

#define fp_f    (2<<(14-1)) /* Using 17.14 fixed point representation. *


A new type "typedef int fixedp;" was created to represent floating point 
numbers as integers in the kernel and implemented in libs/kernel.

A global variable "static fixedp load_avg;" was created in thread.c. It 
holds the load average for the system and is represented by a fixedp type.

The fields "int nice;" and "fixedp recent_cpu" were added to the thread 
struct, which represent the niceness and recent_cpu value of thread 
respectively, to be used in calculating a thread's new priority.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0     0   0   0   63  61  59   A
 4     4   0   0   62  61  59   A
 8     8   0   0   61  61  59   B
12     8   4   0   61  60  59   A
16     12  4   0   60  60  59   B
20     12  8   0   60  59  59   A
24     16  8   0   59  59  59   C
28     16  8   4   59  59  58   B
32     16  12  4   59  58  58   A
36     20  12  4   58  58  58   C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

The only uncertainties were the load_avg, since the problem did not specify its
value, and the behavior under equal priorities. Ths load_avg does not affect
computations on this time interval, so we can safely ignore its value. We assume
that this scheduler, much like the simpler schedulers implemented, operates by
pushing threads to a (sorted) ready queue; in this case, it obeys round-robin
scheduling for threads of equal priority.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

Most of the scheduling occurs on intervals, and thus is placed inside the timer
interrupt. It is likely to degrade performance, but only on the ticks in which
the interval has finished and the mlfqr variables need to be updated.


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?


			  SURVEY QUESTIONS
			  ================

Answering these questions is optional, but it will help us improve the
course in future years.  Feel free to tell us anything you want - these
questions are just to spur your thoughts.  Also, feel free to be completely
honest if there are issues with the assignment or the course - you won't be
penalized.  We can't fix things until we know about them.  :-)

>> In your opinion, was this assignment, or any of the parts of it, too
>> easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Were there any parts of the assignment that you felt were unnecessarily
>> tedious or pointless?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the instructor and/or TAs to more
>> effectively assist students, either for future quarters or the remaining
>> projects?

>> Any other comments?

